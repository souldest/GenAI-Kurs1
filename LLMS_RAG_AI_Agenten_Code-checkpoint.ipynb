{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ec65cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06ec60f72704a3aaa7737d561ec25a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Frage:', layout=Layout(width='70%'), placeholder='Gib deine Frage ein...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925496430d5c4e3eb8e69208c3060b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, continuous_update=False, description='Temperature:', max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a3707461b249c4b095f54b9d3f777e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=150, continuous_update=False, description='Max Tokens:', max=500, min=10, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b294b4e81c45899b2d77cf35ba3d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bbd1667ab24e17a93e375a834cce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Dokumente anzeigen', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396ece30e81449fb8bd1a2366659d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Interaktives Notebook: LLMs, RAG & AI-Agenten (vollst√§ndig)\n",
    "# ---\n",
    "\n",
    "# 1Ô∏è‚É£ Installation & Imports: pip install ipywidgets openai pandas --quiet\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Optional: OpenAI import f√ºr echte LLM-Abfragen\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "# --- CONFIG ---\n",
    "# F√ºr echte OpenAI-Abfragen, setze deinen API-Key:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"DEIN_API_KEY\"\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# 2Ô∏è‚É£ Dummy LLM-Abfrage\n",
    "def llm_query(prompt, temperature=0.5, max_tokens=150):\n",
    "    if OPENAI_AVAILABLE and os.environ.get(\"openai-secret-key\"):\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    else:\n",
    "        responses = {\n",
    "            \"Hallo\": \"Hallo! Wie kann ich dir helfen?\",\n",
    "            \"Was ist RAG?\": \"RAG steht f√ºr Retrieval-Augmented Generation: Dokumente werden durchsucht und f√ºr Antworten genutzt.\",\n",
    "            \"Wer bist du?\": \"Ich bin ein AI-Agent in einem interaktiven Notebook.\"\n",
    "        }\n",
    "        return responses.get(prompt, \"Das kann ich gerade nicht beantworten.\")\n",
    "\n",
    "# 3Ô∏è‚É£ RAG-Demo (kleines Dokumenten-Set)\n",
    "documents = {\n",
    "    \"Doc1\": \"Python ist eine Programmiersprache, die f√ºr KI und Datenanalyse beliebt ist.\",\n",
    "    \"Doc2\": \"RAG kombiniert Dokumentenabruf mit Textgenerierung f√ºr genauere Antworten.\",\n",
    "    \"Doc3\": \"AI-Agenten automatisieren Aufgaben basierend auf Regeln und KI.\"\n",
    "}\n",
    "\n",
    "def rag_search(query):\n",
    "    results = [text for text in documents.values() if query.lower() in text.lower()]\n",
    "    return results if results else [\"Kein Dokument gefunden.\"]\n",
    "\n",
    "# 4Ô∏è‚É£ Interaktiver AI-Agent\n",
    "def ai_agent(query, temperature=0.5, max_tokens=150):\n",
    "    if \"erkl√§re\" in query.lower() or \"wer\" in query.lower() or \"was\" in query.lower():\n",
    "        return llm_query(query, temperature=temperature, max_tokens=max_tokens)\n",
    "    else:\n",
    "        return \"\\n\".join(rag_search(query))\n",
    "\n",
    "# 5Ô∏è‚É£ Widgets\n",
    "# Eingabe der Frage\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Gib deine Frage ein...',\n",
    "    description='Frage:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# LLM-Parameter\n",
    "temperature_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Temperature:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "max_tokens_slider = widgets.IntSlider(\n",
    "    value=150,\n",
    "    min=10,\n",
    "    max=500,\n",
    "    step=10,\n",
    "    description='Max Tokens:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Ausgabe\n",
    "output_box = widgets.Output()\n",
    "\n",
    "def on_submit(change):\n",
    "    with output_box:\n",
    "        clear_output()\n",
    "        query = change['new']\n",
    "        if query.strip() == \"\":\n",
    "            print(\"Bitte gib eine Frage ein.\")\n",
    "            return\n",
    "        answer = ai_agent(query, temperature=temperature_slider.value, max_tokens=max_tokens_slider.value)\n",
    "        print(f\"üìù Antwort:\\n{answer}\")\n",
    "\n",
    "input_box.observe(on_submit, names='value')\n",
    "\n",
    "display(input_box, temperature_slider, max_tokens_slider, output_box)\n",
    "\n",
    "# 6Ô∏è‚É£ Button: Dokumente anzeigen\n",
    "doc_button = widgets.Button(description=\"Dokumente anzeigen\")\n",
    "doc_output = widgets.Output()\n",
    "\n",
    "def show_docs(b):\n",
    "    with doc_output:\n",
    "        clear_output()\n",
    "        df = pd.DataFrame(list(documents.items()), columns=[\"Dokument\", \"Text\"])\n",
    "        display(df)\n",
    "\n",
    "doc_button.on_click(show_docs)\n",
    "display(doc_button, doc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb478fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
